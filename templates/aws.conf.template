# Director 2.3 Config file
# Creates a small cluster including a Cloudera Data Science Workbench gateway node
#
#
# Copyright (c) 2016 Cloudera, Inc. All rights reserved.
#

#
# Simple AWS Cloudera Director configuration file with automatic role assignments
# that works as expected if you use a single instance type for all cluster nodes
#

#
# Cluster name
#
name: CDSW

#
# Cloud provider configuration (credentials, region or zone and optional default image)
#

provider {
    type: aws

    accessKeyId: "REPLACE_ME_AWS_ACCESS_KEY_ID"
    secretAccessKey: "REPLACE_ME_AWS_SECRET_ACCESS_KEY"

    publishAccessKeys: false

    region: "REPLACE_ME_AWS_REGION" # an AWS region such as us-east-1

    subnetId: "REPLACE_ME_SUBNET_ID" # An AWS subnet, such as subnet-e7542291

    securityGroupsIds: "REPLACE_ME_SECURITY_GROUP_ID" # An AWS security group ID, such as sg-891a50f1 - ensure port 7189 is open!

    instanceNamePrefix: ${name}

    associatePublicIpAddresses: true
}

#
# SSH credentials to use to connect to the instances
#

ssh {
    username: centos
    privateKey: """REPLACE_ME_SSH_PRIVATE_KEY"""
}

common-instance-properties {
    image: "REPLACE_ME_AMI_ID" # An AWS AMI, such as ami-40c71256 - best to build this as per https://github.com/cloudera/director-scripts/tree/master/faster-bootstrap
    tags {
        owner: "REPLACE_ME_OWNER"
    }
}
#
# A list of instance types to use for group of nodes or management services
#

instances {
    master : ${common-instance-properties} {
        type: c4.xlarge
        instanceNamePrefix: master-${name}
    }
    worker : ${common-instance-properties} {
        type: c4.xlarge
        instanceNamePrefix: worker-${name} 
    }
    cdsw : ${common-instance-properties} {
        instanceNamePrefix: cdsw-${name}
        type: c4.4xlarge
	rootVolumeSizeGB: 100
	rootVolumeType: gp2
	ebsVolumeCount : 4
	ebsVolumeType: gp2
	ebsVolumeSizeGiB: 500
   }

}


#
# Configuration for Cloudera Manager. Cloudera Director can use an existing instance
# or bootstrap everything from scratch for a new cluster
#

include "kerberos.conf"
cloudera-manager {

    instance: ${instances.master} {
    instanceNamePrefix: cm-${name}
        tags {
            application: "Cloudera Manager 5"
        }
    
   bootstrapScript: """#!/bin/bash -x
yum -y install centos-release-scl wget
cd /tmp
 
wget 'http://archive.cloudera.com/spark2/csd/SPARK2_ON_YARN-2.0.0.cloudera1.jar'
 
mkdir -p /opt/cloudera/csd
chmod 644 SPARK*.jar
mv SPARK*.jar /opt/cloudera/csd/
chown cloudera-scm:cloudera-scm -R /opt/cloudera
exit 0
"""
	}
    krbAdminUsername: ${?krbAdminUsername}
    krbAdminPassword: ${?krbAdminPassword}

   configs {
        # CLOUDERA_MANAGER corresponds to the Cloudera Manager Server configuration options

   	 CLOUDERA_MANAGER {
	    enable_api_debug: false
            custom_banner_html: "Managed by Cloudera Director"
            MANAGES_PARCELS: true
	    enable_faster_bootstrap: true
            KDC_TYPE: ${?KDC_TYPE}
	    KDC_HOST: ${?KDC_HOST}
            SECURITY_REALM: ${?SECURITY_REALM}
            KRB_MANAGE_KRB5_CONF: ${?KRB_MANAGE_KRB5_CONF}
	    # Note use of aes256 - need to ensure ALL cluster members have the necessary JCE policy files.
	    # If you find that you can get a ticket but not use it then this is likely the problem!
            KRB_ENC_TYPES: ${?KRB_ENC_TYPES}
   	}
    }

    #
    # Automatically activate 60-Day Cloudera Enterprise Trial
    #
    enableEnterpriseTrial: true

    repository: "http://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5.10/"
    repositoryKeyUrl: "http://archive.cloudera.com/cm5/redhat/7/x86_64/cm/RPM-GPG-KEY-cloudera"

}

#
# Cluster description
#

cluster {

    products {
      CDH: 5.10 # includes Hive and Spark
      SPARK2: 2
    }


    # S3 Configurations
    configs {
      HDFS {
        core_site_safety_valve: """
            <property>
                <name>fs.s3a.access.key</name>
                <value>REPLACE_ME_AWS_ACCESS_KEY_ID</value>
            </property>
            <property>
                <name>fs.s3a.secret.key</name>
                <value>REPLACE_ME_AWS_SECRET_ACCESS_KEY</value>
            </property>
            <property>
                <name>fs.s3a.block.size</name>
                <value>134217728</value>
            </property>
            <property>
              <name>fs.s3a.server-side-encryption-algorithm</name>
              <value>AES256</value>
            </property>
            <property>
              <name>fs.s3a.connection.ssl.enabled</name>
              <value>true</value>
              <description>Enables or disables SSL connections to S3.</description>
            </property>
        """
      }
    }

    parcelRepositories: ["http://archive.cloudera.com/cdh5/parcels/5.10/", "https://archive.cloudera.com/spark2/parcels/2/"]

    services: [HDFS, YARN, SPARK2_ON_YARN, ]

    masters {
      count: 1
      instance: ${instances.master}

      roles {
        HDFS: [NAMENODE, SECONDARYNAMENODE]
        YARN: [RESOURCEMANAGER, JOBHISTORY]
 	SPARK2_ON_YARN: [SPARK2_YARN_HISTORY_SERVER]
      }
    }

    workers {
      count: 2

      instance: ${instances.worker}

      roles {
        HDFS: [DATANODE]
        YARN: [NODEMANAGER]
      }
    }
    gateways {
      count: 1

      instance: ${instances.cdsw} {
      	bootstrapScript: """#!/bin/bash -x
curl -u cloudera:AskBiggerQuestions -O http://bits.cloudera.com/179e45eb/0.7.3/cloudera-data-science-workbench-0.7.3-1.el7.centos.x86_64.rpm
yum -y localinstall cloudera-data-science-workbench-*.rpm
exit 0
"""
}

      roles {
        HDFS: [GATEWAY]
	YARN: [GATEWAY]
	SPARK2_ON_YARN: [GATEWAY]
      }
    }
    instancePostCreateScripts: ["""/bin/bash -x
echo InstancePostCreateScript
if rpm -q cloudera-data-science-workbench 
then
# Install java using alternatives:
alternatives --install /usr/bin/java java /usr/java/jdk1.7.0_67-cloudera/bin/java 2000

echo "This is the CDSW node"
# install AWS
yum -y install unzip
curl -O "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip"
unzip awscli-bundle.zip
./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws && rm -rf awscli-bundle*

export AWS_ACCESS_KEY_ID='REPLACE_ME_AWS_ACCESS_KEY_ID'
export AWS_SECRET_ACCESS_KEY='REPLACE_ME_AWS_SECRET_ACCESS_KEY'
export AWS_DEFAULT_REGION=us-east-1

PUB_IP=$(/usr/local/bin/aws ec2 describe-instances  --output text --filter Name=private-dns-name,Values=$(hostname -f) | grep ^INSTANCES | cut -f15)
DOM="ec2.${PUB_IP:?}.xip.io"
MASTER=$(hostname -f)
cat /etc/fstab
mount
fdisk -l | grep /dev/xvd
DBD="$(grep '^/dev' /etc/fstab | cut -f1 -d' ' | sort | sed 'N;s/\n/ /' | head -1)"
ABD="$(grep '^/dev' /etc/fstab | cut -f1 -d' ' | sort | sed 'N;s/\n/ /' | tail -1)"
sed -i -e "s/\(DOMAIN=\).*/\1${DOM:?}/" -e "s/\(MASTER_HOSTNAME=\).*/\1${MASTER:?}/"  -e "s@\(DOCKER_BLOCK_DEVICES=\).*@\1\"${DBD:?}\"@" -e "s@\(APPLICATION_BLOCK_DEVICES=\).*@\1\"${ABD:?}\"@" /etc/cdsw/config/cdsw.conf
for dev in $(grep '^/dev' /etc/fstab | cut -f1 -d' '); do umount $dev; done
sed -i '/^\/dev/d' /etc/fstab

# Ensure that cdsw can restart after reboot
# Cannot use sysctl directly since the bridge module isn't loaded until after sysctl
# So load the module early and put the configuration so that sysctl can do its stuff
echo bridge > /etc/modules-load.d/bridge.conf
echo "net.bridge.bridge-nf-call-iptables=1" >>/etc/sysctl.d/bridge.conf
# CDSW prereq
# Ensure that the ipv6 networking is NOT disabled - this can be done at boot time:
echo "net.ipv6.conf.all.disable_ipv6=0" >>/etc/sysctl.conf

## Make sure that we add an auto restart script to the boot sequence
echo "cdsw restart" >> /etc/rc.d/rc.local
chmod a+x /etc/rc.d/rc.local

fi
exit 0
"""]
    postCreateScripts: ["""#!/bin/bash -x
yum -y install epel-release
yum -y install python-pip wget curl jq htop mlocate finger
pip install cm-api
""",
"""#!/usr/bin/python
import os
import time
from cm_api.api_client import ApiResource
# If the exit code is not zero Cloudera Director will fail

# Post creation scripts also have access to the following environment variables:

#    DEPLOYMENT_HOST_PORT
#    ENVIRONMENT_NAME
#    DEPLOYMENT_NAME
#    CLUSTER_NAME
#    CM_USERNAME
#    CM_PASSWORD

def main():
    anaconda_repo='https://repo.continuum.io/pkgs/misc/parcels/'
    anaconda_version='4.0.0'
    cmhost = os.environ['DEPLOYMENT_HOST_PORT'].split(":")[0]
    api = ApiResource(cmhost, username='admin', password='admin')
    all_clusters = api.get_all_clusters()
    for cluster in all_clusters:
        if (cluster.name == os.environ['CLUSTER_NAME']):
            break

    cm = api.get_cloudera_manager()
    config = cm.get_config(view='summary')
    parcel_urls = config.get("REMOTE_PARCEL_REPO_URLS","").split(",")
    print "Adding Anaconda parcel repository"
    if anaconda_repo in parcel_urls:
        # already there, skip
        print "Anaconda repo url already included"
    else:
        parcel_urls.append(anaconda_repo)
        config["REMOTE_PARCEL_REPO_URLS"] = ",".join(parcel_urls)
        cm.update_config(config)
        # wait to make sure parcels are refreshed
        time.sleep(10)
        print "Added Anaconda repository URL"

    # Download Anaconda parcel
    print "Downloading parcel"
    parcel = cluster.get_parcel('Anaconda', anaconda_version)
    parcel.start_download()
    while True:
        parcel = cluster.get_parcel('Anaconda', anaconda_version)
        if parcel.stage == 'DOWNLOADED':
            break
        if parcel.state.errors:
            raise Exception(str(parcel.state.errors))
        print "Downloading  progress: %s of %s" % (parcel.state.progress, parcel.state.totalProgress)
        time.sleep(2)
    print "Downloaded"

    print "Distributing"
    parcel.start_distribution()
    while True:
        parcel = cluster.get_parcel('Anaconda', anaconda_version)
        if parcel.stage == 'DISTRIBUTED':
            break
        if parcel.state.errors:
            raise Exception(str(parcel.state.errors))
        print "Distributing  progress: %s of %s" % (parcel.state.progress, parcel.state.totalProgress)
        time.sleep(5)
    print "Distributed"

    print "Activating Anaconda"
    parcel.activate()
    while True:
        parcel = cluster.get_parcel('Anaconda', anaconda_version)
        if parcel.stage == 'ACTIVATED':
            break
        time.sleep(2)
    print "Activated. Anaconda is ready to use"

    print "Restarting Cluster"
    cluster.restart(redeploy_client_configuration=True).wait()
    print "Cluster Restarted"

    
if __name__ == "__main__":
    exit(main())
"""
]
}
